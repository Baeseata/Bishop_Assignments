{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" phase_1 import modules \"\"\"\n",
    "#import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" phase_2-1 define loading functions \"\"\"\n",
    "def load_data():\n",
    "    global Folders, Path, ID, Act_index, index_loc\n",
    "    '''\n",
    "    output:\n",
    "    Data[i][j][k][m][n](all elements are float 64)\n",
    "    \n",
    "    i:  0 for phone_accel, 1 for phone_gyro\n",
    "        2 for watch_accel, 3 for watch_gyro\n",
    "        \n",
    "    j:  index of subjects, default range between 0 and 51\n",
    "    \n",
    "    k:  activities\n",
    "        \n",
    "        0-A-walking     1-B-jogging     2-C-stairs      3-D-sitting\n",
    "        4-E-standing    5-F-typing      6-G-teeth       7-H-soup\n",
    "        8-I-chips       9-J-pasta       10-K-drinking   11-L-sandwich\n",
    "        12-M-kicking    13-O-catch      14-P-dribbling  15-Q-writing\n",
    "        16-R-calpping   17-S-folding \n",
    "\n",
    "    m:  0 for x_axis, 1 for y_axis, 2 for z_axis\n",
    "    \n",
    "    n:  index of information in time sequence\n",
    "    \n",
    "    (through this funciton, only sensors data are left,\n",
    "    time stamps and others are confiscated)\n",
    "    \n",
    "    '''\n",
    "    Data = []\n",
    "    for i in range(len(Folders)):\n",
    "        print('current folder: %s/%s' % (Folders[i][0], Folders[i][1]))\n",
    "        data = []\n",
    "        for j in range(len(ID)):\n",
    "            array = pd.read_csv(Path % \n",
    "                          (Folders[i][0], Folders[i][1], ID[j],\n",
    "                           Folders[i][1], Folders[i][0]), \n",
    "                           header=None, delimiter=',|;')\n",
    "            array.drop(axis=1, columns=6, inplace=True)\n",
    "            array = np.array(array)\n",
    "            mat = []\n",
    "            for k in range(len(Act_index)):\n",
    "                pos  = [m for m,arr in enumerate(array) if arr[index_loc]==Act_index[k]]\n",
    "                temp = np.array([array[m] for m in pos]).T\n",
    "                temp = np.array(np.delete(temp, [0, 1, 2], axis=0), dtype=float)\n",
    "                mat.append(temp)\n",
    "            data.append(mat)\n",
    "        Data.append(data)\n",
    "    print('loading completed!')\n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" phase_2-2 define window-based-dividing functions \"\"\"\n",
    "def split_data(Data, target=18, subj=51, sens=4, window=10, stride=5, Hz=20):\n",
    "    global Folders\n",
    "    ''' \n",
    "    input:\n",
    "    Data  : outcome from function-load_data()\n",
    "    target: numbers of classification, default = 18\n",
    "    subj  : numbers of subjects, default = 51\n",
    "    sens  : numbers of sensors, default = 4\n",
    "    window: window of sampling length(second)\n",
    "    stride: stride of sampling length(second)\n",
    "    Hz    : sampling Hz, default = 20\n",
    "    \n",
    "    output:\n",
    "    data[i][j][k][l][m][n](all elements are float 64)\n",
    "    \n",
    "    i, j, k, m, n are same as function2-1 'load_data()'\n",
    "    \n",
    "    l:  index of the piece of window in sequence\n",
    "    \n",
    "    '''\n",
    "    data = [] \n",
    "    # data has 4 lists, \n",
    "    # each one for a combination of phone/watch and accel/gyro\n",
    "    for i in range(sens):\n",
    "        print('current data from sensor: %s-%s' % (Folders[i][0],Folders[i][1]))\n",
    "        dat = []\n",
    "        # dat has 18 lists,\n",
    "        # each one for the all the dataset in one activity\n",
    "        for j in range(subj):\n",
    "            matrix = []\n",
    "            # matrix has 51 lists\n",
    "            # each one for an assemblage in one subject\n",
    "            for k in range(target):\n",
    "                mat = []\n",
    "                array = Data[i][j][k].T\n",
    "                length = len(array)\n",
    "                div = (length // (stride * Hz)) - 1\n",
    "                for m in range(div):\n",
    "                    arr = array[(m * stride * Hz):\n",
    "                                (m * stride * Hz + window * Hz)]\n",
    "                    temp = []\n",
    "                    for n in range(3):\n",
    "                        temp.append(arr.T[n] - np.mean(arr.T[n]))\n",
    "                    mat.append(np.array(temp))\n",
    "                matrix.append(mat)\n",
    "            dat.append(matrix)\n",
    "        data.append(dat)\n",
    "    print('splitting completed!')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" phase_2-3 define merging functions \"\"\"\n",
    "def merge_data(Data, target=18, subj=51, sens=4, shuffle=True):\n",
    "    '''\n",
    "    input:\n",
    "    shuffle: whether shuffle or not, default = True\n",
    "    \n",
    "    output_1:\n",
    "    data[i][j][k](all elements are float 64)\n",
    "    \n",
    "    i:  index of dataset, random arranged if shuffle=True\n",
    "    \n",
    "    j:  0, 1, 2 for x,y,z in phone_accel\n",
    "        3, 4, 5 for x,y,z in phone_gyro\n",
    "        6, 7, 8 for x,y,z in watch_accel\n",
    "        9,10,11 for x,y,z in watch_gyro\n",
    "        \n",
    "    k:  default=200 pieces of information\n",
    "        otherwise has window * Hz pieces\n",
    "    \n",
    "    output_2:\n",
    "    target[i]\n",
    "    \n",
    "    i:  corresponding activity classification with data[i][j][k]\n",
    "    \n",
    "    '''\n",
    "    matrix, clas = [], []\n",
    "    data, target = [], []\n",
    "    for k in range(18):\n",
    "        for j in range(51):\n",
    "            length = min(len(Data[0][j][k]),len(Data[1][j][k]),\n",
    "                         len(Data[2][j][k]),len(Data[3][j][k]))\n",
    "            for l in range(length):\n",
    "                temp = np.concatenate((Data[0][j][k][l],\n",
    "                                       Data[1][j][k][l],\n",
    "                                       Data[2][j][k][l],\n",
    "                                       Data[3][j][k][l]))\n",
    "                matrix.append(temp)\n",
    "                clas.append(k)\n",
    "    if shuffle:\n",
    "        index = np.random.permutation(len(clas))   \n",
    "        for i in range(len(index)):\n",
    "            data.append(matrix[index[i]])\n",
    "            target.append(clas[index[i]]) \n",
    "    else:\n",
    "        data = matrix\n",
    "        target = clas\n",
    "    print('merging completed')\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" phase_2-4 define displaying functions \"\"\"\n",
    "def display_raw(arr, index, target, window=[0,10]):\n",
    "    global Folders, axis, Act_names, Hz\n",
    "    '''\n",
    "    input:\n",
    "    arr    : raw original data without preprocessing\n",
    "             (from function2-1 'load_data' )\n",
    "    index  : index of subject\n",
    "    target : class of activity\n",
    "    window : window for viusalising(second)\n",
    "    Hz     : sampling hz, default=20\n",
    "    \n",
    "    output : four figs\n",
    "    '''\n",
    "    plt.figure(figsize=(6,12))\n",
    "    plt.rcParams['figure.dpi']=120\n",
    "    plt.rcParams['savefig.dpi']=120\n",
    "    for i in range(4):\n",
    "        plt.subplot(4,1,i+1)\n",
    "        plt.subplots_adjust(hspace=0.5)\n",
    "        x = np.linspace(0, len(Data[i][index][target][0])/20, \n",
    "                        len(Data[i][index][target][0]))\n",
    "        plt.plot(x, Data[i][index][target][0], color=[0.1,0.3,0.7], \n",
    "                 alpha=0.9, lw=0.5, label='%s' % (axis[0]))\n",
    "        plt.plot(x, Data[i][index][target][1], color=[0.7,0.3,0.1], \n",
    "                 alpha=0.9, lw=0.5, label='%s' % (axis[1]))\n",
    "        plt.plot(x, Data[i][index][target][2], color=[0.1,0.7,0.3], \n",
    "                 alpha=0.9, lw=0.5, label='%s' % (axis[2]))\n",
    "        plt.legend(loc=\"upper right\", fontsize=10)\n",
    "        plt.title('%s - %s, class = %s' % (Folders[i][0],Folders[i][1],\n",
    "                                          Act_names[target]),fontsize=10)\n",
    "        plt.xlim([window[0], window[1]])\n",
    "        plt.ylim([-20, 20])\n",
    "        plt.xlabel('second',fontsize=10)\n",
    "        plt.grid(alpha=0.1)\n",
    "    plt.show()\n",
    "\n",
    "def display_win(arr, target, index):\n",
    "    global Folders, axis, window, Hz\n",
    "    '''\n",
    "    input:\n",
    "    arr    : raw data with preprocessing\n",
    "             (from function2-3 'merge_data' )\n",
    "    index  : index of data\n",
    "    target : class of activity\n",
    "             (from function2-3 'merge_data' )\n",
    "    \n",
    "    output : four figs\n",
    "    \n",
    "    '''\n",
    "    x = np.linspace(0, window, window * Hz)\n",
    "    plt.figure(figsize=(6,12))\n",
    "    plt.rcParams['figure.dpi']=120\n",
    "    plt.rcParams['savefig.dpi']=120\n",
    "    for i in range(4):\n",
    "        plt.subplot(4,1,i+1)\n",
    "        plt.subplots_adjust(hspace=0.5)\n",
    "        plt.plot(x, arr[index][i * 3 + 0], color=[0.1,0.3,0.7], \n",
    "                 alpha=0.7, lw=1.5, label='%s' % (axis[0]))\n",
    "        plt.plot(x, arr[index][i * 3 + 1], color=[0.7,0.3,0.1], \n",
    "                 alpha=0.7, lw=1.5, label='%s' % (axis[1]))\n",
    "        plt.plot(x, arr[index][i * 3 + 2], color=[0.1,0.7,0.3], \n",
    "                 alpha=0.7, lw=1.5, label='%s' % (axis[2]))\n",
    "        plt.legend(loc=\"upper right\", fontsize=10)\n",
    "        plt.title('%s - %s, class = %s' % (Folders[i][0],Folders[i][1],\n",
    "                                          Act_names[target[index]]),fontsize=10)\n",
    "        plt.xlim([0, window])\n",
    "        plt.ylim([-20, 20])\n",
    "        plt.xlabel('second',fontsize=10)\n",
    "        plt.grid(alpha=0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" phase_2-5 define dividing functions \"\"\"\n",
    "def divide_data(Data, target, ratio=0.1):\n",
    "    length = len(Data)\n",
    "    length_train = round(length * (1 - ratio))\n",
    "    train_set = Data[0:(length_train-1)]\n",
    "    train_tar = target[0:(length_train-1)]\n",
    "    test_set = Data[length_train:-1]\n",
    "    test_tar = target[length_train:-1]\n",
    "    return train_set, test_set, train_tar, test_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" phase_3-1 build network \"\"\"\n",
    "class HaiNet(nn.Module):\n",
    "    global window, Hz\n",
    "    def __init__(self):\n",
    "        super(HaiNet, self).__init__()\n",
    "        self.layer_1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=12,out_channels=36,\n",
    "                      kernel_size=5,stride=1,padding=2,bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        self.layer_2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=36,out_channels=72,\n",
    "                      kernel_size=9,stride=1,padding=4,bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(72*(int((window*Hz)/4)), 720)\n",
    "        self.fc2 = nn.Linear(720, 108)\n",
    "        self.fc3 = nn.Linear(108, 18)          \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer_1(x)\n",
    "        out = self.layer_2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" phase_3-2 define loss function \"\"\"\n",
    "def crossloss(output, target):\n",
    "    global Act_index\n",
    "    length = len(Act_index)\n",
    "    tar = np.zeros(length)\n",
    "    tar[target-1] = 1\n",
    "    tar = torch.from_numpy(tar).float()\n",
    "    d = torch.dot(output, tar)\n",
    "    c = - torch.log(d)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" phase_3-3 define softmax function \"\"\"\n",
    "def softmax(output):\n",
    "    global Act_index\n",
    "    out = output[0]\n",
    "    length = len(Act_index)\n",
    "    out_exp = torch.zeros(length)\n",
    "    for i in range(length):\n",
    "        out_exp[i] = torch.exp(out[i])\n",
    "    out_sum = torch.sum(out_exp)\n",
    "    out_prb = torch.zeros(length)\n",
    "    for i in range(length):\n",
    "        out_prb[i] = out_exp[i] / out_sum\n",
    "    return out_prb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" phase_3-4 define correct function \"\"\"\n",
    "def corr(output, target):\n",
    "    global Act_index\n",
    "    length = len(Act_index)\n",
    "    tar = np.zeros(length)\n",
    "    tar[target-1] = 1\n",
    "    out = output.detach().numpy()\n",
    "    out_max = out[0]\n",
    "    max_pos = 0\n",
    "    for i in range(length):\n",
    "        if out[i] > out_max:\n",
    "            out_max = out[i]\n",
    "            max_pos = i\n",
    "    if max_pos == target - 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" phase_3-5 define train function \"\"\"\n",
    "def train(train_data, target):\n",
    "    net.train()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    train_loss = 0\n",
    "    \n",
    "    for i in range(len(train_data)):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        inputs = np.reshape(train_data[i], (1,12,200))\n",
    "        inputs = torch.from_numpy(inputs)\n",
    "        outputs = net(inputs)\n",
    "        outputs = softmax(outputs)\n",
    "        loss = crossloss(outputs, target[i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('%5d / %6d' % (i + 1, len(train_data)))\n",
    "            acc = correct / total\n",
    "            los = train_loss / total\n",
    "            print('acc: %2.2f%%, loss: %1.3f\\n' % (acc * 100, los))\n",
    "\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            train_loss = 0\n",
    "            \n",
    "            \n",
    "        total += 1\n",
    "        correct += corr(outputs, target[i])\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    '''\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    return train_loss, correct, total\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" phase_4 parameters \"\"\"\n",
    "''' \n",
    "file loading part \n",
    "(need global in function definition)\n",
    "\n",
    "'''\n",
    "Path = './raw/%s/%s/data_%d_%s_%s.txt'\n",
    "Folders = (['phone','accel'],['phone','gyro'],\n",
    "           ['watch','accel'],['watch','gyro'])\n",
    "ID = np.linspace(1600, 1650, 51, dtype=int)\n",
    "Act_index = ('A','B','C','D','E','F',\n",
    "             'G','H','I','J','K','L',\n",
    "             'M','O','P','Q','R','S')\n",
    "Act_names = ('walking','jogging','stairs',\n",
    "             'sitting','standing','typing',\n",
    "             'teeth','soup','chips','pasta',\n",
    "             'drinking','sandwich','kicking',\n",
    "             'catch','dribbling','writing',\n",
    "             'clapping','folding')\n",
    "axis = ('x','y','z')\n",
    "index_loc = 1\n",
    "\n",
    "''' \n",
    "model building part \n",
    "(some need global in function definition)\n",
    "'''\n",
    "window = 10\n",
    "stride = 5\n",
    "Hz = 20\n",
    "max_epoch = 10\n",
    "learnR = 0.001\n",
    "net = HaiNet().double()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learnR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" phase_5-1 data loading \"\"\"\n",
    "Data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" phase_5-2 data splitting \"\"\"\n",
    "mat = split_data(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" phase_5-3 data merging \"\"\"\n",
    "matr, target = merge_data(mat)\n",
    "matrix = np.array(matr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set, train_tar, test_tar = divide_data(matrix, target, ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_set = train_set[3000:4000]\n",
    "debug_tar = train_tar[3000:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" phase_6-1 data training \"\"\" \n",
    "train(train_set, train_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossloss(output, target):\n",
    "    global Act_index\n",
    "    length = len(Act_index)\n",
    "    tar = np.zeros(length)\n",
    "    tar[target-1] = 1\n",
    "    tar = torch.from_numpy(tar).double()\n",
    "    out = output[0]\n",
    "    d = torch.dot(out, tar)\n",
    "    c = - torch.log(d)\n",
    "    return c\n",
    "tar = [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "tar = np.array(tar)\n",
    "tar = torch.from_numpy(tar).double()\n",
    "print(tar)\n",
    "brr = arr[0]\n",
    "print(brr)\n",
    "crr = torch.dot(brr, tar)\n",
    "print(crr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_exp = torch.zeros(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(18):\n",
    "    some_exp[i] = torch.exp(brr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som = torch.sum(some_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = torch.zeros(18)\n",
    "for i in range(18):\n",
    "    prob[i] = some_exp[i] / som"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
